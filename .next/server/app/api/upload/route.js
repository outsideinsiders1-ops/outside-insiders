"use strict";(()=>{var a={};a.id=413,a.ids=[413],a.modules={261:a=>{a.exports=require("next/dist/shared/lib/router/utils/app-paths")},10846:a=>{a.exports=require("next/dist/compiled/next-server/app-page.runtime.prod.js")},11997:a=>{a.exports=require("punycode")},16698:a=>{a.exports=require("node:async_hooks")},21820:a=>{a.exports=require("os")},27910:a=>{a.exports=require("stream")},28354:a=>{a.exports=require("util")},29294:a=>{a.exports=require("next/dist/server/app-render/work-async-storage.external.js")},44870:a=>{a.exports=require("next/dist/compiled/next-server/app-route.runtime.prod.js")},55591:a=>{a.exports=require("https")},63033:a=>{a.exports=require("next/dist/server/app-render/work-unit-async-storage.external.js")},74075:a=>{a.exports=require("zlib")},79428:a=>{a.exports=require("buffer")},79551:a=>{a.exports=require("url")},81630:a=>{a.exports=require("http")},83997:a=>{a.exports=require("tty")},86439:a=>{a.exports=require("next/dist/shared/lib/no-fallback-error.external")},89685:(a,b,c)=>{c.r(b),c.d(b,{handler:()=>M,patchFetch:()=>L,routeModule:()=>H,serverHooks:()=>K,workAsyncStorage:()=>I,workUnitAsyncStorage:()=>J});var d={};c.r(d),c.d(d,{OPTIONS:()=>G,POST:()=>F,maxDuration:()=>E});var e=c(95736),f=c(9117),g=c(4044),h=c(39326),i=c(32324),j=c(261),k=c(54290),l=c(85328),m=c(38928),n=c(46595),o=c(3421),p=c(17679),q=c(41681),r=c(63446),s=c(86439),t=c(51356),u=c(53976),v=c(52246),w=c(3195),x=c(68113),y=c(45456),z=c(78940);async function A(a,b,c,d){let e=[];for(let a=0;a<d;a++)e.push(`${c}.chunk.${a}`);try{await a.storage.from(b).remove(e)}catch(a){console.warn("Failed to cleanup chunks:",a)}}var B=c(46931),C=c(96484),D=c(15959);let E=300;async function F(a){let b={"Access-Control-Allow-Origin":"*","Access-Control-Allow-Methods":"POST, OPTIONS","Access-Control-Allow-Headers":"Content-Type"};try{let c,d=await a.formData(),e=d.get("fileUrl"),f=d.get("file"),g=d.get("sourceType")||"State Agency",h=d.get("sourceName")||f?.name||"unknown",i=d.get("defaultState")||null,j=f,k=f?.name||h;if(e)try{console.log(`Downloading file from storage: ${e}`);let a=d.get("filePath")||null,b=!1,c=null,f="uploads",g=null;if(a){let d=(c=a).split("/");f=d.slice(0,-1).join("/")||"uploads",g=d[d.length-1];try{let{data:a,error:c}=await B.w.storage.from("park-uploads").list(f);if(c)console.warn("Could not list directory to check for chunks:",c.message),b=!1;else if(a&&a.length>0){let c=RegExp(`^${g.replace(/[.*+?^${}()|[\]\\]/g,"\\$&")}\\.chunk\\.\\d+$`),d=a.filter(a=>c.test(a.name));(b=d.length>0)?console.log(`Detected ${d.length} chunks for file: ${g}`):console.log(`No chunks found for ${g}, will try to download as regular file`)}else console.log(`No files found in directory ${f}, will try to download as regular file`),b=!1}catch(a){console.warn("Could not check for chunks, will try regular file download:",a.message),b=!1}}if(b&&c){console.log("Detected chunked upload, reassembling chunks..."),console.log("File path:",c);let{data:a,error:b}=await B.w.storage.from("park-uploads").list(f);if(b)throw console.error("Error listing files:",b),Error(`Failed to list chunks: ${b.message}`);console.log(`Listing directory "${f}" - found ${a?.length||0} files`),a&&a.length>0&&console.log("All files in directory:",a.map(a=>a.name));let d=(a||[]).filter(a=>a.name.includes(".chunk."));console.log(`Found ${d.length} total chunk files in directory`),d.length>0&&console.log("Chunk files found:",d.map(a=>a.name));let i=g.replace(/[.*+?^${}()|[\]\\]/g,"\\$&"),l=RegExp(`^${i}\\.chunk\\.\\d+$`),m=(a||[]).filter(a=>{let b=l.test(a.name);return b&&console.log(`Matched chunk: ${a.name}`),b});if(0===m.length&&d.length>0){console.log("No exact matches found, trying to find chunks with any timestamp prefix...");let b=g.replace(/^\d+-/,"").replace(/[.*+?^${}()|[\]\\]/g,"\\$&"),e=RegExp(`^\\d+-${b}\\.chunk\\.\\d+$`),h=(a||[]).filter(a=>{let b=e.test(a.name);return b&&console.log(`Found chunk with flexible pattern: ${a.name}`),b});if(h.length>0){console.log(`Found ${h.length} chunks with flexible pattern matching`);let a=h[0].name.replace(/\.chunk\.\d+$/,"");c=f?`${f}/${a}`:a,g=a,m=h}else if(console.log("Found chunk files but pattern matching failed. Attempting to use any chunk files..."),d.length>0){let a={};d.forEach(b=>{let c=b.name.replace(/\.chunk\.\d+$/,"");a[c]||(a[c]=[]),a[c].push(b)});let b=Object.values(a).sort((a,b)=>b.length-a.length)[0];if(b&&b.length>0){console.log(`Using chunk group with ${b.length} chunks: ${b[0].name.replace(/\.chunk\.\d+$/,"")}`);let a=b[0].name.replace(/\.chunk\.\d+$/,"");c=f?`${f}/${a}`:a,g=a,m=b}}}let n=m.length;if(console.log(`Found ${n} chunks matching pattern for ${g}`),0===n){console.log("No chunks found, trying to download as regular file from storage...");try{let{data:a,error:b}=await B.w.storage.from("park-uploads").download(c);if(b){console.log("Direct download failed, trying public URL...");let a=await fetch(e);if(!a.ok)throw Error(`Failed to download file from storage: ${a.statusText}. File may not exist or chunks may not have been uploaded correctly.`);let b=await a.blob(),c=e.split("/");k=c[c.length-1].split("?")[0]||h,j=new File([b],k,{type:b.type})}else{let b=await a.arrayBuffer();k=g||h,j=new File([b],k,{type:"application/zip"})}}catch(a){throw Error(`Failed to download file: ${a.message}. If this was a chunked upload, ensure all chunks were uploaded successfully.`)}}else{m.sort((a,b)=>{let c=parseInt(a.name.match(/\.chunk\.(\d+)$/)?.[1]||"0"),d=parseInt(b.name.match(/\.chunk\.(\d+)$/)?.[1]||"0");return c-d}),console.log(`Reassembling ${n} chunks from base path: ${c}`);let a=0;try{let{data:b}=await B.w.storage.from("park-uploads").download(`${c}.chunk.0`);b&&(a=(await b.arrayBuffer()).byteLength*n)}catch(a){console.warn("Could not estimate file size:",a)}if(a>0x40000000){let b=(a/0x40000000).toFixed(2);if(console.warn(`âš ï¸ Large file detected: ~${b} GB. This may exceed server memory limits.`),a>0x80000000)throw Error(`File is too large (${b} GB) to process in a single request. Vercel serverless functions have memory limits. Please split the file into smaller parts (<1GB each) or use a different processing method.`)}let b=[],d=m.map(a=>{let b=a.name.match(/\.chunk\.(\d+)$/);return b?parseInt(b[1]):-1}).filter(a=>a>=0).sort((a,b)=>a-b);console.log(`Chunk numbers found: ${d.join(", ")}`),console.log(`Expected range: 0 to ${n-1}`);let e=[];for(let a=0;a<n;a++)d.includes(a)||e.push(a);if(e.length>0)throw Error(`Missing chunks: ${e.join(", ")}. Expected ${n} chunks but found ${d.length}.`);for(let a=0;a<n;a++){let d=`${c}.chunk.${a}`;console.log(`Downloading chunk ${a+1}/${n}: ${d}`);try{let{data:c,error:e}=await B.w.storage.from("park-uploads").download(d);if(e)throw console.error("Chunk download error details:",{chunkPath:d,error:e.message,errorCode:e.statusCode}),Error(`Failed to download chunk ${a+1}/${n} (${d}): ${e.message}`);if(!c)throw Error(`Chunk ${a+1}/${n} returned no data`);let f=await c.arrayBuffer();b.push(f),console.log(`Chunk ${a+1}/${n} downloaded: ${(f.byteLength/1024/1024).toFixed(2)} MB`),((a+1)%10==0||a===n-1)&&console.log(`Downloaded ${a+1}/${n} chunks (${Math.round((a+1)/n*100)}%)`)}catch(b){throw console.error(`Error downloading chunk ${a+1}:`,b),Error(`Failed to download chunk ${a+1}/${n}: ${b.message}`)}}console.log(`All ${n} chunks downloaded. Reassembling...`);let f=b.reduce((a,b)=>a+b.byteLength,0);if(console.log(`Total file size: ${(f/0x40000000).toFixed(2)} GB`),f>1288490188.8)throw Error(`File size (${(f/0x40000000).toFixed(2)} GB) exceeds server memory limits. Vercel serverless functions have memory constraints. Please split the file into smaller parts (<1GB each) or contact support for assistance with very large files.`);let i=new Uint8Array(f),l=0;for(let a of b)i.set(new Uint8Array(a),l),l+=a.byteLength;console.log("File reassembled successfully");let o=new Blob([i]);try{await A(B.w,"park-uploads",c,n),console.log("Chunks cleaned up")}catch(a){console.warn("Failed to cleanup chunks (non-fatal):",a)}k=g||h,j=new File([o],k,{type:o.type||"application/octet-stream"})}}else{console.log("Downloading regular file (not chunked)");let b=null;if(a)try{console.log(`Attempting direct download from path: ${a}`);let{data:c,error:d}=await B.w.storage.from("park-uploads").download(a);if(!d&&c)b=await c.blob(),console.log(`Downloaded file directly: ${(b.size/1024/1024).toFixed(2)} MB`);else if(d){console.warn("Direct download error:",d.message,d.statusCode),console.log("Direct download failed, checking if file might be chunked...");let{data:a}=await B.w.storage.from("park-uploads").list(f);if(a){let b=a.filter(a=>a.name.includes(".chunk."));if(b.length>0)throw console.log(`Found ${b.length} chunk files but pattern didn't match. Chunk files:`,b.slice(0,5).map(a=>a.name)),Error(`File appears to be chunked (found ${b.length} chunk files) but chunk detection failed. Please ensure all chunks were uploaded with the correct naming pattern: ${g}.chunk.0, ${g}.chunk.1, etc.`)}}}catch(a){console.warn("Direct download failed:",a.message)}if(!b){console.log("Trying public URL download...");try{let a=await fetch(e);if(!a.ok){if(400===a.status)throw Error("File not found at public URL (Bad Request). If this was a chunked upload, the chunks may not have been uploaded correctly, or the file may be too large for direct download. Please check that all chunks were uploaded successfully.");throw Error(`Failed to download file from storage: ${a.status} ${a.statusText}`)}b=await a.blob(),console.log(`Downloaded from public URL: ${(b.size/1024/1024).toFixed(2)} MB`)}catch(b){throw Error(`Failed to download file: ${b.message}. If this was a chunked upload, ensure all chunks were uploaded successfully. File path: ${a||"unknown"}`)}}let c=e.split("/");k=c[c.length-1].split("?")[0]||h,j=new File([b],k,{type:b.type||"application/octet-stream"})}}catch(d){console.error("File download/reassembly error:",d);let a=d.message||"Unknown error",c=a;return c=a.includes("memory")||a.includes("too large")?a:a.includes("Failed to download chunk")?`File reassembly failed: ${a}. The file may be too large or some chunks may be missing.`:`Failed to process uploaded file: ${a}`,Response.json({success:!1,error:c,details:void 0},{status:400,headers:b})}if(!j)return Response.json({success:!1,error:"No file provided. Please upload a file or provide a file URL."},{status:400,headers:b});let l=j.size||0,m=d.get("filePath")||null;if(l>524288e3||m){if(console.log(`ðŸ“¦ File is large (${(l/1024/1024).toFixed(2)} MB) or chunked. Queuing for background processing...`),!m)return Response.json({success:!1,error:"Large files must be uploaded in chunks first. Please use the chunked upload feature."},{status:400,headers:b});try{return await D.V.send({name:"file/process",data:{filePath:m,bucketName:"park-uploads",sourceType:g,sourceName:h,defaultState:i}}),Response.json({success:!0,message:"File queued for background processing. This may take several minutes for large files.",backgroundJob:!0,filePath:m},{headers:b})}catch(a){console.error("Failed to queue background job:",a),console.log("Falling back to direct processing...")}}let n=k.toLowerCase();if(n.endsWith(".shp")||n.endsWith(".zip"))try{c=await (0,v.h)(j)}catch(a){return Response.json({success:!1,error:`Failed to parse shapefile: ${a.message}`},{status:400,headers:b})}else try{let a=await j.text();c=JSON.parse(a)}catch{return Response.json({success:!1,error:"Invalid JSON file. Please upload a valid GeoJSON file (.geojson or .json with GeoJSON format)."},{status:400,headers:b})}if(!c.type||!c.features)return Response.json({success:!1,error:'Invalid GeoJSON format. File must have "type" and "features" properties.'},{status:400,headers:b});let o=c.features||[],p=[];console.log(`Processing ${o.length} features from ${h}`);let q=Math.ceil(o.length/1e3);for(let a=0;a<q;a++){let b=1e3*a,c=Math.min(b+1e3,o.length),d=o.slice(b,c);console.log(`Processing batch ${a+1}/${q} (features ${b+1}-${c} of ${o.length})...`);for(let a=0;a<d.length;a++){let c=d[a],e=b+a;if(!c.geometry||!c.properties)continue;let f=null,j=null,k=null;if("Point"===c.geometry.type&&c.geometry.coordinates)j=c.geometry.coordinates[0],f=c.geometry.coordinates[1],k=c.geometry;else if("Polygon"===c.geometry.type||"MultiPolygon"===c.geometry.type){let a=c.geometry.coordinates,b=[],d=[];if("Polygon"===c.geometry.type)for(let c of a)for(let a of c)b.push(a[0]),d.push(a[1]);else if("MultiPolygon"===c.geometry.type)for(let c of a)for(let a of c)for(let c of a)b.push(c[0]),d.push(c[1]);b.length>0&&d.length>0&&(j=b.reduce((a,b)=>a+b,0)/b.length,f=d.reduce((a,b)=>a+b,0)/d.length),k=(0,w.Mp)(c.geometry,152)}let l=c.properties,m=(0,x.G)(l);if(!m.state&&i&&(m.state=i),m.state&&(m.state=(0,C.NC)(m.state)),!m.agency||""===m.agency){let a=m.state||(0,C.NC)(i)||"";g&&a?(m.agency=({"State Agency":`${a} State Parks`,"Public State":`${a} State Parks`,"County Agency":`${a} County Parks`,"City Agency":`${a} City Parks`,"Public Federal":"Federal Agency","Federal Agency":"Federal Agency"})[g]||g,console.log(`Derived agency "${m.agency}" from sourceType "${g}" and state "${a}"`)):m.agency=g||"Unknown Agency"}if(void 0!==m._parkAccess&&null!==m._parkAccess){let a=String(m._parkAccess).trim();if("3"!==a&&"3.0"!==a){console.log(`Skipping park ${m.name}: ParkAccess is ${a}, not 3 (Open Access)`);continue}}delete m._parkAccess,m.data_source||(m.data_source=g||h),m.activities&&!Array.isArray(m.activities)&&(m.activities=[m.activities]),m.amenities&&!Array.isArray(m.amenities)&&(m.amenities=[m.amenities]),e<5&&(0,x.y)(l);let n=null;if(k)try{let a=(0,z.$U)(k);if(!a.valid){console.warn(`Park ${m.name} has invalid geometry: ${a.error}`);let b=(0,z.WC)(k);(0,z.$U)(b).valid?(k=b,console.log(`Fixed geometry for ${m.name}`)):(console.warn(`Could not fix geometry for ${m.name}, skipping geometry`),k=null)}if(k){let a=(0,y.$)(k);a.valid?(n=(0,y.B)(k,4326))||console.warn(`Failed to convert geometry to WKT for ${m.name}`):console.warn(`Geometry validation failed for ${m.name}: ${a.error}`)}}catch(a){console.warn(`Failed to process geometry for ${m.name}:`,a),n=null}let o=m.acres||(l.GIS_Acres?parseFloat(l.GIS_Acres):null)||(l.acres?parseFloat(l.acres):null)||(l.AREA?parseFloat(l.AREA):null)||0,q={...m,latitude:f,longitude:j,acres:o,...n&&{geometry:n}};if(!q.name||"Unnamed Park"===q.name){console.warn("Skipping feature with no name:",c);continue}if((!q.latitude||!q.longitude)&&k&&(console.log(`Park ${q.name} missing coordinates but has geometry - calculating centroid...`),"Polygon"===k.type||"MultiPolygon"===k.type)){let a=k.coordinates,b=[],c=[];if("Polygon"===k.type)for(let d of a)for(let a of d)b.push(a[0]),c.push(a[1]);else if("MultiPolygon"===k.type)for(let d of a)for(let a of d)for(let d of a)b.push(d[0]),c.push(d[1]);b.length>0&&c.length>0&&(q.longitude=b.reduce((a,b)=>a+b,0)/b.length,q.latitude=c.reduce((a,b)=>a+b,0)/c.length,console.log(`Calculated centroid for ${q.name}: (${q.latitude}, ${q.longitude})`))}if(!q.latitude||!q.longitude||isNaN(q.latitude)||isNaN(q.longitude)||q.latitude<-90||q.latitude>90||q.longitude<-180||q.longitude>180){console.warn(`Skipping ${q.name}: Invalid or missing coordinates (${q.latitude}, ${q.longitude})`);continue}p.push(q)}a<q-1&&console.log(`Batch ${a+1} complete. Processed ${p.length} parks so far...`)}console.log(`Grouping ${p.length} parks to remove duplicates...`);let r=new Map;for(let a of p){let b=(0,u.$S)(a.name),c=`${b}_${a.state||"UNKNOWN"}`,d=r.get(c);d?a.acres>(d.acres||0)&&(r.set(c,a),console.log(`Replaced ${a.name} (${d.acres||0} acres) with larger version (${a.acres} acres)`)):r.set(c,a)}let s=Array.from(r.values());if(console.log(`After grouping: ${s.length} unique parks (removed ${p.length-s.length} duplicates)`),0===s.length)return Response.json({success:!1,error:"No valid parks found in file. Ensure features have name and coordinates."},{status:400,headers:b});let t=await (0,u.BN)(s,g);return Response.json({success:!0,message:`Processed ${s.length} parks from ${h}`,parksFound:s.length,parksAdded:t.added,parksUpdated:t.updated,parksSkipped:t.skipped,errors:t.errors.length>0?t.errors:void 0,sourceType:g,sourceName:h},{headers:b})}catch(d){console.error("Upload API Error:",d),console.error("Error stack:",d.stack);let a=d.message||"Unknown error processing file",c=500;return d.message&&d.message.includes("too large")?c=400:d.message&&(d.message.includes("memory")||d.message.includes("timeout"))&&(c=413,a=`File processing failed: ${d.message}. The file may be too large for serverless processing. Consider splitting into smaller files.`),Response.json({success:!1,error:a,details:void 0},{status:c,headers:b})}}async function G(){return new Response(null,{status:200,headers:{"Access-Control-Allow-Origin":"*","Access-Control-Allow-Methods":"POST, OPTIONS","Access-Control-Allow-Headers":"Content-Type"}})}let H=new e.AppRouteRouteModule({definition:{kind:f.RouteKind.APP_ROUTE,page:"/api/upload/route",pathname:"/api/upload",filename:"route",bundlePath:"app/api/upload/route"},distDir:".next",relativeProjectDir:"",resolvedPagePath:"/Users/robertfleming/outside-insiders-current/app/api/upload/route.js",nextConfigOutput:"",userland:d}),{workAsyncStorage:I,workUnitAsyncStorage:J,serverHooks:K}=H;function L(){return(0,g.patchFetch)({workAsyncStorage:I,workUnitAsyncStorage:J})}async function M(a,b,c){var d;let e="/api/upload/route";"/index"===e&&(e="/");let g=await H.prepare(a,b,{srcPage:e,multiZoneDraftMode:!1});if(!g)return b.statusCode=400,b.end("Bad Request"),null==c.waitUntil||c.waitUntil.call(c,Promise.resolve()),null;let{buildId:u,params:v,nextConfig:w,isDraftMode:x,prerenderManifest:y,routerServerContext:z,isOnDemandRevalidate:A,revalidateOnlyGenerated:B,resolvedPathname:C}=g,D=(0,j.normalizeAppPath)(e),E=!!(y.dynamicRoutes[D]||y.routes[C]);if(E&&!x){let a=!!y.routes[C],b=y.dynamicRoutes[D];if(b&&!1===b.fallback&&!a)throw new s.NoFallbackError}let F=null;!E||H.isDev||x||(F="/index"===(F=C)?"/":F);let G=!0===H.isDev||!E,I=E&&!G,J=a.method||"GET",K=(0,i.getTracer)(),L=K.getActiveScopeSpan(),M={params:v,prerenderManifest:y,renderOpts:{experimental:{cacheComponents:!!w.experimental.cacheComponents,authInterrupts:!!w.experimental.authInterrupts},supportsDynamicResponse:G,incrementalCache:(0,h.getRequestMeta)(a,"incrementalCache"),cacheLifeProfiles:null==(d=w.experimental)?void 0:d.cacheLife,isRevalidate:I,waitUntil:c.waitUntil,onClose:a=>{b.on("close",a)},onAfterTaskError:void 0,onInstrumentationRequestError:(b,c,d)=>H.onRequestError(a,b,d,z)},sharedContext:{buildId:u}},N=new k.NodeNextRequest(a),O=new k.NodeNextResponse(b),P=l.NextRequestAdapter.fromNodeNextRequest(N,(0,l.signalFromNodeResponse)(b));try{let d=async c=>H.handle(P,M).finally(()=>{if(!c)return;c.setAttributes({"http.status_code":b.statusCode,"next.rsc":!1});let d=K.getRootSpanAttributes();if(!d)return;if(d.get("next.span_type")!==m.BaseServerSpan.handleRequest)return void console.warn(`Unexpected root span type '${d.get("next.span_type")}'. Please report this Next.js issue https://github.com/vercel/next.js`);let e=d.get("next.route");if(e){let a=`${J} ${e}`;c.setAttributes({"next.route":e,"http.route":e,"next.span_name":a}),c.updateName(a)}else c.updateName(`${J} ${a.url}`)}),g=async g=>{var i,j;let k=async({previousCacheEntry:f})=>{try{if(!(0,h.getRequestMeta)(a,"minimalMode")&&A&&B&&!f)return b.statusCode=404,b.setHeader("x-nextjs-cache","REVALIDATED"),b.end("This page could not be found"),null;let e=await d(g);a.fetchMetrics=M.renderOpts.fetchMetrics;let i=M.renderOpts.pendingWaitUntil;i&&c.waitUntil&&(c.waitUntil(i),i=void 0);let j=M.renderOpts.collectedTags;if(!E)return await (0,o.I)(N,O,e,M.renderOpts.pendingWaitUntil),null;{let a=await e.blob(),b=(0,p.toNodeOutgoingHttpHeaders)(e.headers);j&&(b[r.NEXT_CACHE_TAGS_HEADER]=j),!b["content-type"]&&a.type&&(b["content-type"]=a.type);let c=void 0!==M.renderOpts.collectedRevalidate&&!(M.renderOpts.collectedRevalidate>=r.INFINITE_CACHE)&&M.renderOpts.collectedRevalidate,d=void 0===M.renderOpts.collectedExpire||M.renderOpts.collectedExpire>=r.INFINITE_CACHE?void 0:M.renderOpts.collectedExpire;return{value:{kind:t.CachedRouteKind.APP_ROUTE,status:e.status,body:Buffer.from(await a.arrayBuffer()),headers:b},cacheControl:{revalidate:c,expire:d}}}}catch(b){throw(null==f?void 0:f.isStale)&&await H.onRequestError(a,b,{routerKind:"App Router",routePath:e,routeType:"route",revalidateReason:(0,n.c)({isRevalidate:I,isOnDemandRevalidate:A})},z),b}},l=await H.handleResponse({req:a,nextConfig:w,cacheKey:F,routeKind:f.RouteKind.APP_ROUTE,isFallback:!1,prerenderManifest:y,isRoutePPREnabled:!1,isOnDemandRevalidate:A,revalidateOnlyGenerated:B,responseGenerator:k,waitUntil:c.waitUntil});if(!E)return null;if((null==l||null==(i=l.value)?void 0:i.kind)!==t.CachedRouteKind.APP_ROUTE)throw Object.defineProperty(Error(`Invariant: app-route received invalid cache entry ${null==l||null==(j=l.value)?void 0:j.kind}`),"__NEXT_ERROR_CODE",{value:"E701",enumerable:!1,configurable:!0});(0,h.getRequestMeta)(a,"minimalMode")||b.setHeader("x-nextjs-cache",A?"REVALIDATED":l.isMiss?"MISS":l.isStale?"STALE":"HIT"),x&&b.setHeader("Cache-Control","private, no-cache, no-store, max-age=0, must-revalidate");let m=(0,p.fromNodeOutgoingHttpHeaders)(l.value.headers);return(0,h.getRequestMeta)(a,"minimalMode")&&E||m.delete(r.NEXT_CACHE_TAGS_HEADER),!l.cacheControl||b.getHeader("Cache-Control")||m.get("Cache-Control")||m.set("Cache-Control",(0,q.getCacheControlHeader)(l.cacheControl)),await (0,o.I)(N,O,new Response(l.value.body,{headers:m,status:l.value.status||200})),null};L?await g(L):await K.withPropagatedContext(a.headers,()=>K.trace(m.BaseServerSpan.handleRequest,{spanName:`${J} ${a.url}`,kind:i.SpanKind.SERVER,attributes:{"http.method":J,"http.target":a.url}},g))}catch(b){if(b instanceof s.NoFallbackError||await H.onRequestError(a,b,{routerKind:"App Router",routePath:D,routeType:"route",revalidateReason:(0,n.c)({isRevalidate:I,isOnDemandRevalidate:A})}),E)throw b;return await (0,o.I)(N,O,new Response(null,{status:500})),null}}},94735:a=>{a.exports=require("events")}};var b=require("../../../webpack-runtime.js");b.C(a);var c=b.X(0,[873,505,372,992,708,702],()=>b(b.s=89685));module.exports=c})();